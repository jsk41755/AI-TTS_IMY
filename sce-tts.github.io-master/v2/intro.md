# 들어가며

지난 2017년과 2018년, 네이버에서 진행하는 개발자 컨퍼런스인 DEVIEW에서 아주
흥미로운 발표가 있었습니다.

- [2017년 '책 읽어주는 딥러닝' - 데브시스터즈 / 김태훈님](https://deview.kr/2017/schedule/182)
- [2018년 '누구나 만드는 내 목소리 합성기' - 네이버 / 이봉준님](https://deview.kr/2018/schedule/247)

위 두 발표에서는 머신 러닝을 통해 TTS를 만드는 과정과 그 결과를 공유하고 있었습니다.

> '책 읽어주는 딥러닝' 발표 영상 (영상 볼륨이 좀 작습니다)

<div class="video-container">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/klnfWhPGPRs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

당시 저는 이 발표들을 보며 머신 러닝으로 준수한 품질을 보여주는 TTS를 만들
수 있다는 사실에 상당히 놀랐습니다. 이 발표를 보기 이전에는 개인이 직접 TTS를
만든다는 건 상상도 못할 만큼 어려운 일이라고 생각했기 때문입니다.

특히 '책 읽어주는 딥러닝'의 김태훈님이 만든 TTS처럼 **다른 누군가의 도움 없이**
**개인이 직접 TTS를 만들 수 있는 방법이 있다**는 점은 저에게 굉장히 매력적으로
느껴졌습니다.

게다가 김태훈님은 '책 읽어주는 딥러닝'에서 사용한 코드를
[오픈 소스로 공개](https://github.com/carpedm20/multi-Speaker-tacotron-tensorflow)
하셨기 때문에, 저도 직접 따라해볼 수 있을 것 같았습니다.

---

하지만, 실제로는 공개된 코드를 따라 TTS를 잘 만들 수 없었습니다.

개인이 자신의 목소리로 문장을 읽어주는 **TTS를 만들기 위해 필요한 것이**
**생각보다 많다**는 것을 알게 되었기 때문입니다. 즉, 제가 원하는 수준의 TTS를
만들기 위해서는 많은 준비가 필요하고 단순히 누군가 만들어 둔 코드를 실행하기만
하는 수준이 아니었던 겁니다.

TTS를 만든다는 것은 제가 취미 수준으로 가볍게 시도해보기에는 너무나 많은 시간
투자가 필요했고, 당시에는 정확히 제가 뭘 해야 TTS를 만들 수 있는지도 잘
몰랐습니다. 결국 저는 저의 목소리로 TTS를 만들 수 있는 가능성이 있다는 정도만
이해한 상태였기 때문에 더 많은 공부가 필요했습니다.

---

그 후, 2020년 중순이 되어서야 몇번의 시행착오 끝에 의미 있는 수준의 성능을
보여주는 TTS 모델을 학습시킬 수 있었습니다.

그리고, 저처럼 누군가 자신의 목소리로 TTS를 만들고자 하는 사람을 위해 제가
TTS를 만들기 위해 사용한 코드와 TTS 제작 방법 등의 결과물을 SCE-TTS 프로젝트를
통해 공유하고자 합니다.

이 문서에서는 제가 실제로 사용한 데이터와 코드를 공개하고, 다른 분들도 이를
쉽게 따라하여 자신만의 TTS를 만들어보실 수 있도록 가이드를 제공합니다. 이
문서가 저처럼 자신의 목소리로 TTS를 만들어 사용하시고자 하는 분들에게 도움이
되면 좋겠습니다.